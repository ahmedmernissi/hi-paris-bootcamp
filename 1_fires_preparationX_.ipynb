{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <a>\n",
    "    <img src=\"./figures/logo-hi-paris-retina.png\" alt=\"Logo\" width=\"280\" height=\"180\">\n",
    "  </a>\n",
    "\n",
    "  <h3 align=\"center\">Data Science Bootcamp</h3>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup\n",
    "First let's save the work to your own working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r ./* ~/my_work/ \n",
    "\"\"\"\n",
    "cp : copy \n",
    "-r : recursively \n",
    "./* all the files in current folder\n",
    "~/my_work : to the my_work folder located at the root of the system\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jdcal\n",
      "  Using cached jdcal-1.4.1-py2.py3-none-any.whl (9.5 kB)\n",
      "Installing collected packages: jdcal\n",
      "Successfully installed jdcal-1.4.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jdcal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Now go to your directory \"my_work\" and start there.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Data cleaning\n",
    "======\n",
    "\n",
    "#### How can it be problematic for our analyst to use the dataset as is, without cleaning? \n",
    "\n",
    "#### WHAT IS DATA CLEANING:\n",
    "The purpose of this step is to normalize the data to facilitate its manipulation during the analysis.\n",
    "Several operations are possible: modify or delete data that are incorrect, incomplete, irrelevant, corrupted, duplicated or badly formatted\n",
    "\n",
    "### Why is this important? \n",
    "- Correct duplicate or misfiled data. \n",
    "- Correct errors in manual data entry. \n",
    "- Wrong data can affect the results and their accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need to import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context and files for this Lab\n",
    "======\n",
    "\n",
    "Multiple datasets will be used to compute features for the final model. All raw datasets are located in `./data/1_raw/`\n",
    "\n",
    "- **Fires** --> **this dataset will be cleaned in this notebook.**\n",
    "    - location: `./data/1_raw/fires/fires_train.csv`\n",
    "    - This table includes wildfire data for the period of 2011-2014 compiled from US federal, state, and local reporting systems.\n",
    "    - Columns are :\n",
    "        * `FOD_ID` = Global unique identifier.\n",
    "        * `FIRE_SIZE` = Estimate of acres within the final perimeter of the fire.\n",
    "        * `FIRESIZECLASS` = Code for fire size based on the number of acres within the final fire perimeter expenditures (A=greater than 0 but less than or equal to 0.25 acres, B=0.26-9.9 acres, C=10.0-99.9 acres, D=100-299 acres, E=300 to 999 acres, F=1000 to 4999 acres, and G=5000+ acres).\n",
    "        * `FIRE_NAME` = Name of the incident, from the fire report (primary) or ICS-209 report (secondary).\n",
    "        * `FIRE_YEAR` = Calendar year in which the fire was discovered or confirmed to exist.\n",
    "        * `DISCOVERY_DATE` = Date on which the fire was discovered or confirmed to exist. `Warning`: date is in Julian format.\n",
    "        * `DISCOVERY_TIME` = Time of day that the fire was discovered or confirmed to exist. `Warning`: Format is HHMM. Ex: 5:30PM will be \"1730\".\n",
    "        * `CONT_DATE` = Date on which the fire was declared contained or otherwise controlled. `Warning`: date is in Julian format.\n",
    "        * `CONT_TIME` = Time of day that the fire was declared contained or otherwise controlled (hhmm where hh=hour, mm=minutes). `Warning`: Format is HHMM. Ex: 5:30PM will be \"1730\".\n",
    "        * `LATITUDE` = Latitude (NAD83) for point location of the fire (decimal degrees).\n",
    "        * `LONGITUDE` = Longitude (NAD83) for point location of the fire (decimal degrees).\n",
    "        * `STATE` = Two-letter alphabetic code for the state in which the fire burned (or originated), based on the nominal designation in the fire report.\n",
    "        * `CAUSE_CODE` = Code for the cause of the fire.\n",
    "        * `CAUSE_DESCR` = Description of the cause of the fire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print the first 5 rows of the dataframe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOD_ID</th>\n",
       "      <th>FIRE_NAME</th>\n",
       "      <th>FIRE_YEAR</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>DISCOVERY_TIME</th>\n",
       "      <th>CONT_DATE</th>\n",
       "      <th>CONT_TIME</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>CAUSE_DESCR</th>\n",
       "      <th>CAUSE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20020059</td>\n",
       "      <td>VFD BEAR CREEK #1</td>\n",
       "      <td>2011</td>\n",
       "      <td>2455641.5</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>2455641.5</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>A</td>\n",
       "      <td>60.246389</td>\n",
       "      <td>-149.349444</td>\n",
       "      <td>AK</td>\n",
       "      <td>accidental</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20020060</td>\n",
       "      <td>CPR LNDG ORGANIC DMP</td>\n",
       "      <td>2011</td>\n",
       "      <td>2455666.5</td>\n",
       "      <td>1812.0</td>\n",
       "      <td>2455669.5</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>A</td>\n",
       "      <td>60.475833</td>\n",
       "      <td>-149.752500</td>\n",
       "      <td>AK</td>\n",
       "      <td>accidental</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20020061</td>\n",
       "      <td>TOKLAT WAY DEBRIS</td>\n",
       "      <td>2011</td>\n",
       "      <td>2455692.5</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>2455692.5</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>A</td>\n",
       "      <td>60.514444</td>\n",
       "      <td>-149.467500</td>\n",
       "      <td>AK</td>\n",
       "      <td>accidental</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20020062</td>\n",
       "      <td>LAWING DRIVE</td>\n",
       "      <td>2011</td>\n",
       "      <td>2455694.5</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>2455694.5</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>A</td>\n",
       "      <td>60.399722</td>\n",
       "      <td>-149.360833</td>\n",
       "      <td>AK</td>\n",
       "      <td>accidental</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20020063</td>\n",
       "      <td>RUSSIAN RIVER TRAIL</td>\n",
       "      <td>2011</td>\n",
       "      <td>2455759.5</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2455759.5</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>A</td>\n",
       "      <td>60.467500</td>\n",
       "      <td>-149.973056</td>\n",
       "      <td>AK</td>\n",
       "      <td>accidental</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FOD_ID             FIRE_NAME  FIRE_YEAR  DISCOVERY_DATE  DISCOVERY_TIME  \\\n",
       "0  20020059     VFD BEAR CREEK #1       2011       2455641.5          1212.0   \n",
       "1  20020060  CPR LNDG ORGANIC DMP       2011       2455666.5          1812.0   \n",
       "2  20020061    TOKLAT WAY DEBRIS        2011       2455692.5          1250.0   \n",
       "3  20020062          LAWING DRIVE       2011       2455694.5          1220.0   \n",
       "4  20020063   RUSSIAN RIVER TRAIL       2011       2455759.5          1020.0   \n",
       "\n",
       "   CONT_DATE  CONT_TIME  FIRE_SIZE FIRE_SIZE_CLASS   LATITUDE   LONGITUDE  \\\n",
       "0  2455641.5     1618.0        0.1               A  60.246389 -149.349444   \n",
       "1  2455669.5     1156.0        0.1               A  60.475833 -149.752500   \n",
       "2  2455692.5     1331.0        0.1               A  60.514444 -149.467500   \n",
       "3  2455694.5     1250.0        0.1               A  60.399722 -149.360833   \n",
       "4  2455759.5     1230.0        0.1               A  60.467500 -149.973056   \n",
       "\n",
       "  STATE CAUSE_DESCR  CAUSE_CODE  \n",
       "0    AK  accidental           1  \n",
       "1    AK  accidental           1  \n",
       "2    AK  accidental           1  \n",
       "3    AK  accidental           1  \n",
       "4    AK  accidental           1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py:3081\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3082\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:101\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:4554\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:4562\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: False",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprint the first 5 rows of the dataframe\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m display(fires\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m----> 5\u001b[0m fires\u001b[38;5;241m.\u001b[39mloc[\u001b[43mfires\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFOD_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m201508655\u001b[39;49m\u001b[43m]\u001b[49m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py:3024\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3024\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3026\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py:3083\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3081\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3082\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3083\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tolerance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3086\u001b[0m     tolerance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_tolerance(tolerance, np\u001b[38;5;241m.\u001b[39masarray(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: False"
     ]
    }
   ],
   "source": [
    "# show fires_days_train\n",
    "fires = pd.read_csv(\"./data/1_raw/fires/fires.csv\")\n",
    "print('print the first 5 rows of the dataframe')\n",
    "display(fires.head())\n",
    "fires.loc[fires['FOD_ID'== 201508655]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **External data** --> **Multiple datasets that will be cleaned and merged with another notebook:** `2_external_data_preparation.ipynb`\n",
    "    - Temperature and precipitation\n",
    "        - The `./data/1_raw/cities/` folder contains temperature and precipitation values for 210 US cities.\n",
    "        - it contains a file `./data/1_raw/cities/city_info.csv` that maps the city name with a code (example: \"USW00094728\" for \"New York\")\n",
    "        - a README file `./data/1_raw/cities/README.txt` can give you additional information on these files.\n",
    "        - all other files are named with a city code (example: `./data/1_raw/cities/USW00094728.csv` for \"New York\") and contains historical temperature and precipitations between **1894** and **2021**, if available.\n",
    "    - Demographics\n",
    "        - The `./data/1_raw/demographics/us-cities-demographics.csv` file contains demographic data (age, total population, etc.) for US cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City infos: print the first 5 rows of the dataframe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>ID</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Stn.Name</th>\n",
       "      <th>Stn.stDate</th>\n",
       "      <th>Stn.edDate</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Lander</td>\n",
       "      <td>USW00024021</td>\n",
       "      <td>42.8153</td>\n",
       "      <td>-108.7261</td>\n",
       "      <td>LANDER WBO</td>\n",
       "      <td>1892-01-01</td>\n",
       "      <td>5/28/1946</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Lander</td>\n",
       "      <td>USW00024021</td>\n",
       "      <td>42.8153</td>\n",
       "      <td>-108.7261</td>\n",
       "      <td>LANDER HUNT FIELD</td>\n",
       "      <td>5/29/1946</td>\n",
       "      <td>12/31/2021</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cheyenne</td>\n",
       "      <td>USW00024018</td>\n",
       "      <td>41.1519</td>\n",
       "      <td>-104.8061</td>\n",
       "      <td>CHEYENNE WBO</td>\n",
       "      <td>1871-01-01</td>\n",
       "      <td>8/31/1935</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cheyenne</td>\n",
       "      <td>USW00024018</td>\n",
       "      <td>41.1519</td>\n",
       "      <td>-104.8061</td>\n",
       "      <td>CHEYENNE MUNICIPAL ARPT</td>\n",
       "      <td>9/1/1935</td>\n",
       "      <td>12/31/2021</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Wausau</td>\n",
       "      <td>USW00014897</td>\n",
       "      <td>44.9258</td>\n",
       "      <td>-89.6256</td>\n",
       "      <td>Wausau Record Herald</td>\n",
       "      <td>1896-01-01</td>\n",
       "      <td>12/31/1941</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Name           ID      Lat       Lon  \\\n",
       "0           1    Lander  USW00024021  42.8153 -108.7261   \n",
       "1           2    Lander  USW00024021  42.8153 -108.7261   \n",
       "2           3  Cheyenne  USW00024018  41.1519 -104.8061   \n",
       "3           4  Cheyenne  USW00024018  41.1519 -104.8061   \n",
       "4           5    Wausau  USW00014897  44.9258  -89.6256   \n",
       "\n",
       "                  Stn.Name  Stn.stDate  Stn.edDate  Unnamed: 8  \n",
       "0               LANDER WBO  1892-01-01   5/28/1946       False  \n",
       "1        LANDER HUNT FIELD   5/29/1946  12/31/2021       False  \n",
       "2             CHEYENNE WBO  1871-01-01   8/31/1935       False  \n",
       "3  CHEYENNE MUNICIPAL ARPT    9/1/1935  12/31/2021       False  \n",
       "4     Wausau Record Herald  1896-01-01  12/31/1941       False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One example of a city file (USW00094728): print the first 5 rows of the dataframe\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>prcp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1869-01-01</td>\n",
       "      <td>29.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1869-01-02</td>\n",
       "      <td>27.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1869-01-03</td>\n",
       "      <td>35.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1869-01-04</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1869-01-05</td>\n",
       "      <td>43.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date  tmax  tmin  prcp\n",
       "0           1  1869-01-01  29.0  19.0  0.75\n",
       "1           2  1869-01-02  27.0  21.0  0.03\n",
       "2           3  1869-01-03  35.0  27.0  0.00\n",
       "3           4  1869-01-04  37.0  34.0  0.18\n",
       "4           5  1869-01-05  43.0  37.0  0.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show Temperature and precipitation\n",
    "\n",
    "# city infos\n",
    "city_infos = pd.read_csv(\"./data/1_raw/cities/city_info.csv\")\n",
    "print('City infos: print the first 5 rows of the dataframe')\n",
    "display(city_infos.head())\n",
    "\n",
    "# one file with temperature and precipitation\n",
    "city_example = pd.read_csv(\"./data/1_raw/cities/USW00094728.csv\")\n",
    "print('One example of a city file (USW00094728): print the first 5 rows of the dataframe')\n",
    "display(city_example.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **fires_days_train** --> **This dataset is already cleaned and will not be used during this first lab**\n",
    "    - location: `./data/1_raw/fires/fires_days_train.csv`\n",
    "    - This table says if at least 1 fire of class size B or bigger was reported for a given date (between 2011 and 2014), in a given state (all US states). Combinations for states and dates are also given for 2015, where predictions will be made in the end. As a consequence, the target value `FIRE` is null in 2015.\n",
    "    - It contains 3 columns:\n",
    "        * `DISCOVERY_DATE` = Date (format: YYYY-mm-dd)\n",
    "        * `STATE` = 2 letters abbreviation for the US state\n",
    "        * `FIRE` = binary target value\n",
    "            - 1 if a fire of class size B or bigger is reported in the given state, at the given date (fires of class A are not considered)\n",
    "            - 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print the first 5 rows of the dataframe (target value is available)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>FIRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>AK</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MI</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MO</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>IL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DISCOVERY_DATE STATE  FIRE\n",
       "0     2011-01-01    AK   0.0\n",
       "1     2011-01-01    MN   0.0\n",
       "2     2011-01-01    MI   0.0\n",
       "3     2011-01-01    MO   1.0\n",
       "4     2011-01-01    IL   0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print the last 5 rows of the dataframe (target value is unavailable)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>FIRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94947</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>PR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94948</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>RI</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94949</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>VT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94950</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>MA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94951</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>DE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DISCOVERY_DATE STATE  FIRE\n",
       "94947     2015-12-31    PR   NaN\n",
       "94948     2015-12-31    RI   NaN\n",
       "94949     2015-12-31    VT   NaN\n",
       "94950     2015-12-31    MA   NaN\n",
       "94951     2015-12-31    DE   NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show fires_days_train\n",
    "fires_days = pd.read_csv(\"./data/1_raw/fires/fires_days_train.csv\", parse_dates=[\"DISCOVERY_DATE\"])\n",
    "print('print the first 5 rows of the dataframe (target value is available)')\n",
    "display(fires_days.head())\n",
    "print('print the last 5 rows of the dataframe (target value is unavailable)')\n",
    "display(fires_days.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warm-up\n",
    "===========\n",
    "\n",
    "#### Useful functions from the pandas library (see below for some examples):\n",
    "- to read a csv file, one can use the function [pd.read_csv()](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html). Some parameters will help you adapt the behaviour of this function (see above documentation for further details):\n",
    "    * delimiter\n",
    "    * parse_dates\n",
    "    * index_col\n",
    "- to save a pandas DataFrame \"df\" into a csv file, one can use the function [.to_csv()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html). We strongly recommend to use the parameter index=False if you are using a default index for your DataFrame.\n",
    "- If you want to access part of a DataFrame based on labels (column name or row name), you can use [.loc()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html)\n",
    "- Similarly, you can access part of a DataFrame based on indexing (column number or row number), you can use [.iloc()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>FIRE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>AK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>MN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>MI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>MO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>IL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18975</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>PR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18976</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>RI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18977</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>VT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18978</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18979</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>DE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18980 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DISCOVERY_DATE STATE  FIRE\n",
       "0         2015-01-01    AK     0\n",
       "1         2015-01-01    MN     0\n",
       "2         2015-01-01    MI     0\n",
       "3         2015-01-01    MO     0\n",
       "4         2015-01-01    IL     0\n",
       "...              ...   ...   ...\n",
       "18975     2015-12-31    PR     0\n",
       "18976     2015-12-31    RI     0\n",
       "18977     2015-12-31    VT     0\n",
       "18978     2015-12-31    MA     0\n",
       "18979     2015-12-31    DE     0\n",
       "\n",
       "[18980 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part of the DataFrame, using .loc()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DISCOVERY_DATE STATE\n",
       "0     2015-01-01    AK\n",
       "1     2015-01-01    MN\n",
       "2     2015-01-01    MI\n",
       "3     2015-01-01    MO\n",
       "4     2015-01-01    IL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part of the DataFrame, using .iloc()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DISCOVERY_DATE STATE\n",
       "0     2015-01-01    AK\n",
       "1     2015-01-01    MN\n",
       "2     2015-01-01    MI\n",
       "3     2015-01-01    MO\n",
       "4     2015-01-01    IL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read a csv file, and store it into a DataFrame \"example_df\"\n",
    "relative_path_file = \"./data/4_predictions/example_submission.csv\"\n",
    "example_df = pd.read_csv(relative_path_file)\n",
    "\n",
    "# show DataFrame\n",
    "print(\"Raw DataFrame\")\n",
    "display(example_df)\n",
    "\n",
    "# display only DISCOVERY_DATE and STATE columns, and the first 5 rows, using .loc()\n",
    "# For .loc[:4, [\"col1\", \"col2\"]]\n",
    "# \":4\" indicates that we select all rows until the row named 4 included (indexing starts at 0)\n",
    "# and [\"col1\", \"col2\"] indicates that we select only col1 and col2\n",
    "loc_df = example_df.loc[:4, [\"DISCOVERY_DATE\", \"STATE\"]]\n",
    "print(\"Part of the DataFrame, using .loc()\")\n",
    "display(loc_df)\n",
    "\n",
    "# Similarly, display only DISCOVERY_DATE and STATE columns, and the first 5 rows, using .iloc()\n",
    "# For .iloc[:, [0, 1]]\n",
    "# \":5\" indicates that we select all rows until row number 5 excluded (indexing starts at 0),\n",
    "# and [0, 1] indicates that we select only columns 0 and 1, that corresponds to DISCOVERY_DATE and STATE\n",
    "iloc_df = example_df.iloc[:5, [0, 1]]\n",
    "print(\"Part of the DataFrame, using .iloc()\")\n",
    "display(iloc_df)\n",
    "\n",
    "# store \"loc_df\"\" into a csv file, without the index\n",
    "# you can see the result by opening the file \"./data/6_test/example_df.csv\" after execution\n",
    "loc_df.to_csv(\"./data/6_test/example_df.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectives of this Notebook\n",
    "======\n",
    "\n",
    "Objectives:\n",
    "- Read the fires dataset `./data/1_raw/fires/fires_train.csv`\n",
    "- Analyze it, to find duplicate values, columns' types, numerical and categorical distributions\n",
    "- Clean it accordingly in order to obtain a quality dataset, without errors, duplicates, irrelevant values... ready to be analyzed. Cleaning can consist in removing, correcting or imputing data.\n",
    "- Save the cleaned DataFrame in `./data/2_clean/fires.csv`\n",
    "\n",
    "\n",
    "##### One can find bellow some guidelines for this process:\n",
    "\n",
    "##### Step 1. Analyze the dataset\n",
    "- Check columns' types with [.info()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html)\n",
    "- Check duplicate values with [.duplicated()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html)\n",
    "- Check numerical data distribution with [.describe()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html)\n",
    "- Check categorical data distribution with [.value_counts()](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html)\n",
    "\n",
    "##### Step 2. Cleaning\n",
    "- Replace/remove missing values\n",
    "    - Impute new values with [.fillna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html)\n",
    "        - Option 1: with statistical data (mean, median, etc.)\n",
    "        - Option 2: with a dedicated flag (e.g. 0, etc.)  \n",
    "    - Option 3: If relevant, drop observations with [.dropna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) function.\n",
    "- Remove irrelevant data, if any (check that all columns are needed). To drop a column, use [.drop(columns=[...])](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html)\n",
    "- If relevant, remove duplicate rows with [.drop_duplicates()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html)\n",
    " perform type conversion with [.astype()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html)\n",
    "- If relevant, fix discovered typos. One way of doing so is by using the [.replace()](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.replace.html) function for pandas Series.\n",
    "- If relevant, Map categorical data into smaller groups by using the [.map()](https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <a>\n",
    "    <img src=\"./figures/UpToYou.png\" alt=\"Logo\" width=\"200\" height=\"280\">\n",
    "  </a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from utils import check_duplicates\n",
    "from jdcal import gcal2jd, jd2gcal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input files/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"./data/1_raw/fires/fires.csv\" # path input file\n",
    "dest_file = \"./data/2_clean/fires.csv\" # path output file\n",
    "checks = {True:\"OK\", False: \"NOK\"} # dict to convert boolean to string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Preparation of the fires dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 295854 entries, 0 to 295853\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   FOD_ID           295854 non-null  int64  \n",
      " 1   FIRE_NAME        231566 non-null  object \n",
      " 2   FIRE_YEAR        295854 non-null  int64  \n",
      " 3   DISCOVERY_DATE   295854 non-null  float64\n",
      " 4   DISCOVERY_TIME   232769 non-null  float64\n",
      " 5   CONT_DATE        221214 non-null  float64\n",
      " 6   CONT_TIME        203999 non-null  float64\n",
      " 7   FIRE_SIZE        295854 non-null  float64\n",
      " 8   FIRE_SIZE_CLASS  295854 non-null  object \n",
      " 9   LATITUDE         295854 non-null  float64\n",
      " 10  LONGITUDE        295854 non-null  float64\n",
      " 11  STATE            295854 non-null  object \n",
      " 12  CAUSE_DESCR      295854 non-null  object \n",
      " 13  CAUSE_CODE       295854 non-null  int64  \n",
      "dtypes: float64(7), int64(3), object(4)\n",
      "memory usage: 31.6+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CODE HERE\n",
    "fires.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         False\n",
       "1         False\n",
       "2         False\n",
       "3         False\n",
       "4         False\n",
       "          ...  \n",
       "295849    False\n",
       "295850    False\n",
       "295851    False\n",
       "295852    False\n",
       "295853    False\n",
       "Length: 295854, dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fires.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2011, 3, 21, 0.0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "str() argument 2 must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(b)\n\u001b[1;32m      6\u001b[0m c\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(b[\u001b[38;5;241m0\u001b[39m]),\u001b[38;5;28mstr\u001b[39m(b[\u001b[38;5;241m1\u001b[39m]),\u001b[38;5;28mstr\u001b[39m(b[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m date\u001b[38;5;241m=\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mdate(\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      8\u001b[0m date\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: str() argument 2 must be str, not int"
     ]
    }
   ],
   "source": [
    "\n",
    "# import module\n",
    "import jdcal as j\n",
    "# declare function\n",
    "b= j.jd2gcal(2400000.5,55641.0)\n",
    "print(b)\n",
    "c=str(b[0]),str(b[1]),str(b[2])\n",
    "date=datetime.date(str(b[0],b[1],b[2]))\n",
    "date.strftime('%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take Away\n",
    "- Edit variable types / formats\n",
    "- Identify duplicates\n",
    "- Delete columns with many missing values\n",
    "- Use common sense and keep only relevant variables\n",
    "- Observe the distribution of values of a variable\n",
    "- Visual representations are useful to understand how a variable works\n",
    "\n",
    "### Pitfalls to avoid\n",
    "- Automatically delete a duplicate: understand why the duplicate appeared\n",
    "- Automatically delete all rows with missing values and lose information. Approximating some values allows you to keep information to meet an objective.\n",
    "- Automatically delete outliers: understand where they come from, are they errors or do they only represent extreme cases?\n",
    "- Retain variables that could be harmful to the ethics of a project (skin color, address...)\n",
    "\n",
    "### Go Further :\n",
    "- [The Ultimate Guide to Data Cleaning](https://towardsdatascience.com/the-ultimate-guide-to-data-cleaning-3969843991d4)\n",
    "- [Learn Data Cleaning Tutorials | Kaggle](https://www.kaggle.com/learn/data-cleaning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6f17db48aa853750bfee38181acc93506773951f4f6f179b65dfa4e5104417bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
